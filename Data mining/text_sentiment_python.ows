<?xml version='1.0' encoding='utf-8'?>
<scheme version="2.0" title="" description="">
	<nodes>
		<node id="0" name="CSV File Import" qualified_name="Orange.widgets.data.owcsvimport.OWCSVFileImport" project_name="Orange3" version="" title="CSV File Import" position="(56.0, 65.0)" />
		<node id="1" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Python Script" position="(272.0, 65.0)" />
		<node id="2" name="Select Columns" qualified_name="Orange.widgets.data.owselectcolumns.OWSelectAttributes" project_name="Orange3" version="" title="Select Columns" position="(161.5, 68.0)" />
		<node id="3" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Python Script (1)" position="(81.0, 183.0)" />
		<node id="4" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (3)" position="(204.0, 192.0)" />
		<node id="5" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Count" position="(600.0, 98.0)" />
		<node id="6" name="CSV File Import" qualified_name="Orange.widgets.data.owcsvimport.OWCSVFileImport" project_name="Orange3" version="" title="sentiment train" position="(413.0, 73.0)" />
		<node id="7" name="CSV File Import" qualified_name="Orange.widgets.data.owcsvimport.OWCSVFileImport" project_name="Orange3" version="" title="sentiment test" position="(409.0, 156.0)" />
		<node id="8" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (4)" position="(743.0, 86.0)" />
		<node id="9" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (5)" position="(619.0, 190.0)" />
		<node id="10" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="TF " position="(613.0, 295.0)" />
		<node id="11" name="CSV File Import" qualified_name="Orange.widgets.data.owcsvimport.OWCSVFileImport" project_name="Orange3" version="" title="sentiment train (1)" position="(412.0, 284.0)" />
		<node id="12" name="CSV File Import" qualified_name="Orange.widgets.data.owcsvimport.OWCSVFileImport" project_name="Orange3" version="" title="sentiment test (1)" position="(408.0, 367.0)" />
		<node id="13" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (4) (1)" position="(763.0, 276.0)" />
		<node id="14" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (5) (1)" position="(622.0, 417.0)" />
	</nodes>
	<links>
		<link id="0" source_node_id="0" sink_node_id="2" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="1" source_node_id="2" sink_node_id="1" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="2" source_node_id="3" sink_node_id="4" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="3" source_node_id="6" sink_node_id="5" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="4" source_node_id="7" sink_node_id="5" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="5" source_node_id="5" sink_node_id="8" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="6" source_node_id="7" sink_node_id="9" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="7" source_node_id="11" sink_node_id="10" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="8" source_node_id="12" sink_node_id="10" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="9" source_node_id="10" sink_node_id="13" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="10" source_node_id="12" sink_node_id="14" source_channel="Data" sink_channel="Data" enabled="true" />
	</links>
	<annotations />
	<thumbnail />
	<node_properties>
		<properties node_id="0" format="literal">{'_session_items': [], '_session_items_v2': [({'type': 'AbsPath', 'path': '/Users/mac/work/school/2022-1/dmine/data mining material/data/text_sentiment_train.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''}), ({'type': 'AbsPath', 'path': '/Users/mac/Desktop/review_shopping.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''})], 'compatibility_mode': False, 'controlAreaVisible': True, 'dialog_state': {'directory': '/Users/mac/work/school/2022-1/dmine', 'filter': 'Text - comma separated (*.csv, *)'}, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\xd3\x00\x00\x00\xc6\x00\x00\x03\x1f\x00\x00\x02=\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x18\x00\x00\x02=\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x1f\x00\x00\x02=', '__version__': 3}</properties>
		<properties node_id="1" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 12, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00N\x00\x00\x00\x19\x00\x00\x04\xb0\x00\x00\x03\x1f\x00\x00\x00N\x00\x00\x005\x00\x00\x04\xb0\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00N\x00\x00\x005\x00\x00\x04\xb0\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}], 'scriptText': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\n\n#tokenize text column\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(df[\'text_tokens\'])\n\n# print(cvec.vocabulary_)\n \ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out())\n\ndff =pd.DataFrame(cvec.transform(df[\'text_tokens\']).toarray(), columns=cvec.get_feature_names_out())\ndf3 = pd.concat([df[\'text_tokens\'],df[\'sentiment\'],dff],ignore_index=False ,axis=1)\n\n#classficiation stages\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\n\n\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = model.predict(my_bow)\nprint(my_predictions)\n\nout_data = table_from_frame(df3)', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="2" format="pickle">gASV9wEAAAAAAAB9lCiMC2F1dG9fY29tbWl0lIiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNpZ25v
cmVfbmV3X2ZlYXR1cmVzlImME3NhdmVkV2lkZ2V0R2VvbWV0cnmUQ0IB2dDLAAMAAAAAAUAAAACT
AAADvwAAAo4AAAFAAAAArwAAA78AAAKOAAAAAAAAAAAFAAAAAUAAAACvAAADvwAAAo6UjBJ1c2Vf
aW5wdXRfZmVhdHVyZXOUiYwLX192ZXJzaW9uX1+USwGMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVv
cmFuZ2V3aWRnZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojBFkb21h
aW5fcm9sZV9oaW50c5R9lCiMBHRleHSUSwGGlIwJYXR0cmlidXRllEsAhpSMCXNlbnRpbWVudJRL
AYaUaBVLAYaUdUr+////hpRoB0sBdYwKYXR0cmlidXRlc5R9lChoE0sBaBdLAXWMBW1ldGFzlH2U
dWJoDCmBlH2UKGgPfZQoaBF9lCiMCXNlbnRpbWVudJRLAYaUaBVLAIaUjAR0ZXh0lEsDhpSMBG1l
dGGUSwCGlHVK/v///4aUaAdLAXVoG32UjAlzZW50aW1lbnSUSwFzaB19lIwEdGV4dJRLA3N1YmV1
Lg==
</properties>
		<properties node_id="3" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 12, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x9d\x00\x00\x00\x19\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x9d\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x9d\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}], 'scriptText': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\n \n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\n\n\nmy_text = \'ดี มากมากครับที่ส่งไวมากดี ครับ ครับ\'\nmy_tokens = text_process(my_text)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform([my_tokens])\n#print(cvec.vocabulary_)\ncc =pd.Series([my_tokens, my_tokens])\nprint(cc)\nmy_bow = cvec.transform(cc)\nprint(my_bow)\nf1 =pd.DataFrame(my_bow.toarray(), columns=cvec.get_feature_names_out())\n\nserie = pd.Series(my_tokens)\nd = {\'text_tokens\': serie}\nf2 = pd.DataFrame(data=d)\ndf3 = pd.concat([f1,f2],ignore_index=False ,axis=1)\nout_data = table_from_frame(df3)', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="4" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x19\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00-\x00\x00\x04\xff\x00\x00\x02\xc7\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f', 'select_rows': True, 'selected_cols': None, 'selected_rows': None, 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="5" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 13, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00N\x00\x00\x00\x19\x00\x00\x04\xb0\x00\x00\x03\x1f\x00\x00\x00N\x00\x00\x005\x00\x00\x04\xb0\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00N\x00\x00\x005\x00\x00\x04\xb0\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'thaitoken2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}], 'scriptText': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\n\n# function to return a list of tokens(not stop words) from a setence\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\n#clear screen\nprint(\'complete\')\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\n\n#get thai stop words\nthai_stopwords = list(thai_stopwords())\n \ntable1      = in_datas[0]\ntable2      = in_datas[1]\n\nif(table1 is None):\n    out_data = None\nif(table2 is None):\n    out_data = None\n\ndf1         = table_to_frame(table1)\ndf2         = table_to_frame(table2)\n\n \n#t1. okenize text column\ndf1[\'text_tokens\'] = df1[\'text\'].apply(text_process)\ndf2[\'text_tokens\'] = df2[\'text\'].apply(text_process)\n\n#2. dataframe X\nX = df1[[\'text_tokens\']]\n\n#series sentiment\n#y = df1[\'sentiment\']\ntoken_col1       = df1[\'text_tokens\']\nsentiment_col1   = df1[\'sentiment\']\n\ntoken_col2       = df2[\'text_tokens\']\nsentiment_col2   = df2[\'sentiment\']\n\n#3. create word vector process\nvector = CountVectorizer(analyzer=lambda x:x.split(\' \'))\n\n#4. fit transforms vector\n#vector.fit_transform(X)\nvector.fit_transform(token_col1)\n\n#print vectors frequency\n#print(vector.vocabulary_)\n\n\ntrain_bow       = vector.transform(token_col1)\n \nmTrainBow       = train_bow.toarray()\n\ncolumn_names    = vector.get_feature_names_out()\n\nmatrix          = pd.DataFrame(mTrainBow, columns= column_names)\n\noutframe        = pd.concat([token_col1,sentiment_col1,matrix],ignore_index=False ,axis=1)\n\n\nmodel = LogisticRegression()\n\nmodel.fit(train_bow, sentiment_col1 )\n\n# # model = svm.SVC(kernel=\'rbf\')\n# # model.fit(train_bow, y)\n# test_bow              = vector.transform(token_col2)\n# test_predictions      = model.predict(test_bow)\n \n\ntest_bow                = vector.transform(token_col2)\ndf2[\'predictions\']      = model.predict(test_bow)\n#print(classification_report(df2[\'predictions\'], df2[\'sentiment\']))\n \n\n\nout_data = table_from_frame(df2)', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="6" format="literal">{'_session_items': [], '_session_items_v2': [({'type': 'AbsPath', 'path': '/Users/mac/work/school/2022-1/dmine/data mining material/data/text_sentiment_train.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''}), ({'type': 'AbsPath', 'path': '/Users/mac/Desktop/review_shopping.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''})], 'compatibility_mode': False, 'controlAreaVisible': True, 'dialog_state': {'directory': '/Users/mac/work/school/2022-1/dmine', 'filter': 'Text - comma separated (*.csv, *)'}, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\xd3\x00\x00\x00\xc6\x00\x00\x03\x1f\x00\x00\x02=\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x18\x00\x00\x02=\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x1f\x00\x00\x02=', '__version__': 3}</properties>
		<properties node_id="7" format="literal">{'_session_items': [], '_session_items_v2': [({'type': 'AbsPath', 'path': '/Users/mac/work/school/2022-1/dmine/data mining material/data/text_sentiment_test.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''}), ({'type': 'AbsPath', 'path': '/Users/mac/work/school/2022-1/dmine/data mining material/data/text_sentiment_train.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''}), ({'type': 'AbsPath', 'path': '/Users/mac/Desktop/review_shopping.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''})], 'compatibility_mode': False, 'controlAreaVisible': True, 'dialog_state': {'directory': '/Users/mac/work/school/2022-1/dmine', 'filter': 'Text - comma separated (*.csv, *)'}, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\xd3\x00\x00\x00\xc6\x00\x00\x03\x1f\x00\x00\x02=\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x18\x00\x00\x02=\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x1f\x00\x00\x02=', '__version__': 3}</properties>
		<properties node_id="8" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x19\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00-\x00\x00\x04\xff\x00\x00\x02\xc7\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="9" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x19\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="10" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 13, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00M\x00\x00\x00\x19\x00\x00\x04\xaf\x00\x00\x03\x1f\x00\x00\x00M\x00\x00\x005\x00\x00\x04\xaf\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00M\x00\x00\x005\x00\x00\x04\xaf\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'thaitoken2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}], 'scriptText': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\n\n# function to return a list of tokens(not stop words) from a setence\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\n#clear screen\nprint(\'complete\')\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\n\n#get thai stop words\nthai_stopwords = list(thai_stopwords())\n\ntable1      = in_datas[0]\ntable2      = in_datas[1]\n\nif(table1 is None):\n    out_data = None\nif(table2 is None):\n    out_data = None\n\ndf1         = table_to_frame(table1)\ndf2         = table_to_frame(table2)\n\n\n#tokenize text column\ndf1[\'text_tokens\'] = df1[\'text\'].apply(text_process)\ndf2[\'text_tokens\'] = df2[\'text\'].apply(text_process)\n# dataframe X\nX = df1[[\'text_tokens\']]\n\n#series sentiment\n#y = df1[\'sentiment\']\ntoken_col1       = df1[\'text_tokens\']\nsentiment_col1   = df1[\'sentiment\']\n\ntoken_col2       = df2[\'text_tokens\']\nsentiment_col2   = df2[\'sentiment\']\n\n#create word vector process\nvector = TfidfVectorizer(analyzer=lambda x:x.split(\' \'))\n\n#fit transforms vector\n#vector.fit_transform(X)\nvector.fit_transform(token_col1)\n\n#print vectors frequency\n#print(vector.vocabulary_)\n\n\ntrain_bow       = vector.transform(token_col1)\n \nmTrainBow       = train_bow.toarray()\n\ncolumn_names    = vector.get_feature_names_out()\n\nmatrix          = pd.DataFrame(mTrainBow, columns= column_names)\n\noutframe        = pd.concat([token_col1,sentiment_col1,matrix],ignore_index=False ,axis=1)\n\n\nmodel = LogisticRegression()\n\nmodel.fit(train_bow, sentiment_col1 )\n\n# # model = svm.SVC(kernel=\'rbf\')\n# # model.fit(train_bow, y)\n# test_bow            = vector.transform(token_col2)\n# test_predictions    = model.predict(test_bow)\n \n\ntest_bow = vector.transform(token_col2)\ndf2[\'predictions\'] = model.predict(test_bow)\nprint(classification_report(df2[\'predictions\'], df2[\'sentiment\']))\n\n#df2[\'predict\'] = token_col1.apply(fly)\n\n#my_text = \'ดีมากครับส่งไว\'\n#my_tokens = text_process(my_text)\n#my_bow = vector.transform(pd.Series([my_tokens]))\n#my_predictions = model.predict(my_bow)\n#print(my_predictions)\n\n\nout_data = table_from_frame(df2)', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="11" format="literal">{'_session_items': [], '_session_items_v2': [({'type': 'AbsPath', 'path': '/Users/mac/work/school/2022-1/dmine/data mining material/data/text_sentiment_train.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''}), ({'type': 'AbsPath', 'path': '/Users/mac/Desktop/review_shopping.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''})], 'compatibility_mode': False, 'controlAreaVisible': True, 'dialog_state': {'directory': '/Users/mac/work/school/2022-1/dmine', 'filter': 'Text - comma separated (*.csv, *)'}, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\xd3\x00\x00\x00\xc6\x00\x00\x03\x1f\x00\x00\x02=\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x18\x00\x00\x02=\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x1f\x00\x00\x02=', '__version__': 3}</properties>
		<properties node_id="12" format="literal">{'_session_items': [], '_session_items_v2': [({'type': 'AbsPath', 'path': '/Users/mac/work/school/2022-1/dmine/data mining material/data/text_sentiment_test.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''}), ({'type': 'AbsPath', 'path': '/Users/mac/work/school/2022-1/dmine/data mining material/data/text_sentiment_train.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''}), ({'type': 'AbsPath', 'path': '/Users/mac/Desktop/review_shopping.csv'}, {'encoding': 'utf-8', 'delimiter': '\t', 'quotechar': '"', 'doublequote': True, 'skipinitialspace': True, 'quoting': 0, 'columntypes': [{'start': 0, 'stop': 2, 'value': 'Categorical'}], 'rowspec': [{'start': 0, 'stop': 1, 'value': 'Header'}], 'decimal_separator': '.', 'group_separator': ''})], 'compatibility_mode': False, 'controlAreaVisible': True, 'dialog_state': {'directory': '/Users/mac/work/school/2022-1/dmine', 'filter': 'Text - comma separated (*.csv, *)'}, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\xd3\x00\x00\x00\xc6\x00\x00\x03\x1f\x00\x00\x02=\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x18\x00\x00\x02=\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x01\xd3\x00\x00\x00\xe2\x00\x00\x03\x1f\x00\x00\x02=', '__version__': 3}</properties>
		<properties node_id="13" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x19\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00-\x00\x00\x04\xff\x00\x00\x02\xc7\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="14" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00Q\x00\x00\x002\x00\x00\x05P\x00\x00\x038\x00\x00\x00Q\x00\x00\x00N\x00\x00\x05P\x00\x00\x038\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00Q\x00\x00\x00N\x00\x00\x05P\x00\x00\x038', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
	</node_properties>
	<session_state>
		<window_groups />
	</session_state>
</scheme>
