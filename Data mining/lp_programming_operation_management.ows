<?xml version='1.0' encoding='utf-8'?>
<scheme version="2.0" title="" description="">
	<nodes>
		<node id="0" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="resource allocation for car manufacturing" position="(218.0, 70.0)" />
		<node id="1" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="maximize profit from  pizza making problem" position="(210.0, 175.0)" />
		<node id="2" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Minimize Inventory cost for sale inventory control problem" position="(210.0, 408.0)" />
		<node id="3" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="yearly inventory model" position="(475.0, 409.0)" />
		<node id="4" name="Edit Domain" qualified_name="Orange.widgets.data.oweditdomain.OWEditDomain" project_name="Orange3" version="" title="Edit Domain (1)" position="(343.5, 409.0)" />
		<node id="5" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="part allocation for washing machine manufacturing" position="(212.0, 282.0)" />
		<node id="6" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="template for simple deicison variable" position="(415.0, 80.0)" />
	</nodes>
	<links>
		<link id="0" source_node_id="2" sink_node_id="4" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="1" source_node_id="4" sink_node_id="3" source_channel="Data" sink_channel="Data" enabled="true" />
	</links>
	<annotations>
		<text id="0" type="text/plain" rect="(164.0, 4.0, 331.0, 54.0)" font-family=".AppleSystemUIFont" font-size="16">Linear Programming Problem using PULIP</text>
	</annotations>
	<thumbnail />
	<node_properties>
		<properties node_id="0" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 14, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00M\x00\x00\x00\x19\x00\x00\x04\xaf\x00\x00\x03\x1f\x00\x00\x00M\x00\x00\x005\x00\x00\x04\xaf\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00M\x00\x00\x005\x00\x00\x04\xaf\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'thaitoken2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp1', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}], 'scriptText': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="1" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 15, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00N\x00\x00\x00\x19\x00\x00\x04\xb0\x00\x00\x03\x1f\x00\x00\x00N\x00\x00\x005\x00\x00\x04\xb0\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00N\x00\x00\x005\x00\x00\x04\xb0\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'thaitoken2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp1', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp2', 'script': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'filename': None}], 'scriptText': '\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'pizza production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nC =     LpVariable(\'C\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30;\nprofitB = 40;\nprofitC = 50;\n#objective function\nmodel += profitA*A +profitB*B+profitC*C\n\n# Constraints\nmodel += 1* A+0.5 *B+1*C &lt;= 30\nmodel += 1* A+ 2* B+2*C &lt;= 90\nmodel += 1* A+ 1* B+1*C &lt;= 21\nprint(model)\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Pizza A = {}".format(A.varValue) )\nprint("Production of Pizza B = {}".format(B.varValue) )\nprint("Production of Pizza C = {}".format(C.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="2" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 16, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x05\x00\x00\x00\x19\x00\x00\x04\xf9\x00\x00\x03\x1f\x00\x00\x00\x05\x00\x00\x005\x00\x00\x04\xf9\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x05\x00\x00\x005\x00\x00\x04\xf9\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'thaitoken2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp1', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp2', 'script': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'filename': None}, {'name': 'lp3', 'script': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'filename': None}], 'scriptText': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\n# Import PuLP modeler functions\nfrom pulp import *\n\n# Creates a list of the quarters\nQuarters = [\'Q1\', \'Q2\', \'Q3\', \'Q4\']\n\n# A dictionary of the demand for each quarter\nDemand = {\'Q1\': 40, \n          \'Q2\': 60, \n          \'Q3\': 75, \n          \'Q4\': 25 }\n\n# Create the \'prob\' object to contain the problem data\nprob = LpProblem("Sailco Inventory", LpMinimize)\n\n# Dictionaries created to contain the referenced Variables\nreg_prod   = LpVariable.dicts("RegProduction"      ,Quarters,0)\novt_prod   = LpVariable.dicts("OverTimeProduction" ,Quarters,0)\ninventory  = LpVariable.dicts("Inventory"          ,Quarters,0)\nprint(reg_prod)\n# The objective function is added to \'prob\' first\nprob += lpSum([400*reg_prod[q] + 452*ovt_prod[q] + 20*inventory[q] for q in Quarters]), "Total Cost"\n\n# The four constraints are added to \'prob\'\nprob += reg_prod[\'Q1\'] + ovt_prod[\'Q1\'] + inventory[\'Q4\'] - inventory[\'Q1\'] == Demand[\'Q1\'], "Q1Balance"\nprob += reg_prod[\'Q2\'] + ovt_prod[\'Q2\'] + inventory[\'Q1\'] - inventory[\'Q2\'] == Demand[\'Q2\'], "Q2Balance"\nprob += reg_prod[\'Q3\'] + ovt_prod[\'Q3\'] + inventory[\'Q2\'] - inventory[\'Q3\'] == Demand[\'Q3\'], "Q3Balance"\nprob += reg_prod[\'Q4\'] + ovt_prod[\'Q4\'] + inventory[\'Q3\'] - inventory[\'Q4\'] == Demand[\'Q4\'], "Q4Balance"\n\n# Regular production upper bounds\nprob += reg_prod[\'Q1\'] &lt;= 50, "Q1RegProductionLimit"\nprob += reg_prod[\'Q2\'] &lt;= 50, "Q2RegProductionLimit"\nprob += reg_prod[\'Q3\'] &lt;= 50, "Q3RegProductionLimit"\nprob += reg_prod[\'Q4\'] &lt;= 50, "Q4RegProductionLimit"\n\n# The problem data is written to an .lp file\nprob.writeLP("/Users/mac/Desktop/SailcoInventory.lp")\n\n# The problem is solved using PuLP\'s choice of Solver\nprob.solve()\nlist1 = [\n          \n         ]\n# The status of the solution is printed to the screen\nprint ("Status:", LpStatus[prob.status])\n\n# Each of the variables is printed with it\'s resolved optimum value\nqr = 1\ncount = 0\nrow = {}\nnum_quater= 4\nfor v in prob.variables():\n    print( v.name, "=", v.varValue)\n    attr = str(qr)\n    row[attr] = v.varValue\n    qr = qr+1\n    if(qr&gt; num_quater):\n        list1.append(row)\n        count = count+1\n        qr=1\n        row = {}\n\nprint(list1)\nprint ("Total Cost = ", value(prob.objective))\n \n\ndf=pd.DataFrame(list1)\ndf[\'production_type\'] = [\'Inventory\',\'Over time\',\'Regular\']\nout_data = table_from_frame(df)', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="3" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x00\x00\x00\x00\x19\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f\x00\x00\x00\x00\x02\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00\x005\x00\x00\x04\xff\x00\x00\x03\x1f', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="4" format="pickle">gASVfwMAAAAAAAB9lCiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNzYXZlZFdpZGdldEdlb21ldHJ5
lENCAdnQywADAAAAAABzAAAAeQAABIsAAAKpAAAAcwAAAJUAAASLAAACqQAAAAAAAAAABQAAAABz
AAAAlQAABIsAAAKplIwLX192ZXJzaW9uX1+USwKMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVvcmFu
Z2V3aWRnZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojBRfZG9tYWlu
X2NoYW5nZV9zdG9yZZR9lCiMBlN0cmluZ5SMBXRvcGljlCmJh5SGlF2UjA1Bc0NhdGVnb3JpY2Fs
lCmGlGFoEIwEdGFnc5QpiYeUhpRdlGgVKYaUYWgQjARsaW5rlCmJh5SGlF2UaBUphpRhjAZTdHJp
bmeUjAdjb21tZW50lCmJh5SGlF2UjA1Bc0NhdGVnb3JpY2FslCmGlGFoIYwKY29tbWVudF9ub5Qp
iYeUhpRdlIwMQXNDb250aW51b3VzlCmGlGGMBFJlYWyUKIwBMZRLA4wBZpSGlCmJdJSGlF2UjAZS
ZW5hbWWUjAJRMZSFlIaUYWguKIwBMpRLA2gwhpQpiXSUhpRdlGg1jAJRMpSFlIaUYWguKIwBM5RL
A2gwhpQpiXSUhpRdlGg1jAJRM5SFlIaUYWguKIwBNJRLA2gwhpQpiXSUhpRdlGg1jAJRNJSFlIaU
YXVK/v///4aUjBZfbWVyZ2VfZGlhbG9nX3NldHRpbmdzlH2USvz///+GlIwOX3NlbGVjdGVkX2l0
ZW2UaElLAoaUSv7///+GlIwRb3V0cHV0X3RhYmxlX25hbWWUjACUSv7///+GlGgESwJ1jAphdHRy
aWJ1dGVzlH2UKGgvSwJoOUsCaEFLAmhJSwJ1jAVtZXRhc5R9lIwPcHJvZHVjdGlvbl90eXBllEsD
c3ViaAkpgZR9lChoDH2UKGgOfZQoaBNdlGgWYWgZXZRoG2FoHl2UaCBhaCRdlGgnYWgqXZRoLWFo
M12UaDhhaDxdlGhAYWhEXZRoSGFoTF2UaFBhdUr+////hpRoUn2USvz///+GlGhVaElLAoaUSv7/
//+GlGhYaFlK/v///4aUaARLAnVoW32UKGgvSwJoOUsCaEFLAmhJSwJ1aF19lHViZXUu
</properties>
		<properties node_id="5" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 16, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x05\x00\x00\x00\x19\x00\x00\x04\xf9\x00\x00\x03\x1f\x00\x00\x00\x05\x00\x00\x005\x00\x00\x04\xf9\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x05\x00\x00\x005\x00\x00\x04\xf9\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'thaitoken2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp1', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp2', 'script': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'filename': None}, {'name': 'lp3', 'script': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'filename': None}], 'scriptText': 'from pulp import *\n#2. create model\nmodel = LpProblem(\'Washing machine productions\',sense=LpMaximize)\n#3. create variables for support number of cake and pie\nA = LpVariable(\'A\', lowBound =0, upBound=None, cat=\'Integer\')\nK = LpVariable(\'K\', lowBound =0, upBound=None, cat=\'Integer\')\nmodel += 350*A + 300*K\n#4. create constraints\nmodel += 18*A + 12*K &lt;= 3132\nmodel += 6*A + 8*K   &lt;= 1440\nmodel += A+K         &lt;= 200\nmodel.solve()\n\nprint(LpStatus[model.status])\narkels = A.varValue;\nkallexs = K.varValue;\nprint("#Arkel model = {}".format(arkels))\nprint("#Kallex = {}".format(kallexs))\nprint("Total Profit {}".format(value(model.objective)))\nprint("====production planning========")\n\nlabours = 18*arkels + 12*kallexs\nrubber_housings = 6*arkels + 8*kallexs  \ndrums = arkels+kallexs  \nprint("days for labours: {}".format(labours))\nprint("days for all rubber_housings: {}".format(rubber_housings))\nprint("days for drums: {}".format(drums))', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="6" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 16, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x05\x00\x00\x00\x19\x00\x00\x04\xf9\x00\x00\x03\x1f\x00\x00\x00\x05\x00\x00\x005\x00\x00\x04\xf9\x00\x00\x03\x1f\x00\x00\x00\x00\x00\x00\x00\x00\x05\x00\x00\x00\x00\x05\x00\x00\x005\x00\x00\x04\xf9\x00\x00\x03\x1f', 'scriptLibrary': [{'name': 'get week', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'elbow', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n#df = df.drop_duplicates(keep='first')\ndf['week'] = df['date'].dt.isocalendar().week\n#here you go\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'warehouse', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n\nretail= table_to_frame(in_data)\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\n\nrfm_m = retail.groupby('CustomerID')['Amount'].sum()\nrfm_m = rfm_m.reset_index()\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()\nrfm_f = rfm_f.reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\n\nrfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')\n\nmax_date = max(retail['InvoiceDate'])\nretail['Diff'] = max_date - retail['InvoiceDate']\nrfm_p = retail.groupby('CustomerID')['Diff'].min()\nrfm_p = rfm_p.reset_index()\nrfm_p['Diff'] = rfm_p['Diff'].dt.days\nrfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')\nrfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']\n#here you go\nout_data = table_from_frame(rfm)", 'filename': None}, {'name': 'warehouse2', 'script': "\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import combinations \nfrom sklearn.cluster import KMeans\nimport folium\n\ndata= table_to_frame(in_data)\n# Color options\ncolor_options = {'demand': 'red',\n                 'supply': 'yellow',\n                 'flow': 'black',\n                 'cog': 'blue',\n                 'candidate': 'black',\n                 'other': 'gray'}\n\ndef fun1(x):\n    if x == 'Supply':\n        return 1.0\n    elif x == 'Demand':\n        return 2.0\n    else:\n        return 0\n \ndata['a1'] = data['type'].apply(fun1).astype(np.int64)\ndata['a2'] = data['volume'].astype(np.int64)\n \ndata['cal_vol'] = data['a1']*data['a2']\ndata=data.drop(['a1','a2'], axis=1)\n\ncands = data.loc[data['type'].str.lower()=='candidate']\nlocs = data.loc[data['cal_vol']&gt;0]\n\nprint(cands)\n#print(locs)\nout_data = table_from_frame(data)", 'filename': None}, {'name': 'addFeatures', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\n#introduce a new feature\ndf['total'] = df['qty'] * df['price']\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getAddtionalFeatures', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\n\nlist = []\n\nbranches = ["branch1", "branch2", "branch3", "branch4"]\npayment_methods = ["cash", "bank transfer", "credit card"]\n\nfor tran_id in range(1, 8406):\n    tran = {\n        "branch": random.choice(branches),\n        "payment_methods": random.choice(payment_methods)\n    }\n    list.append(tran)\n\ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMoreRows', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'bkk\', \'phuket\']\nlist = []\nfor tran_id in range(10001, 10100+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month == 1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month == 2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n    \ndf = pd.DataFrame.from_dict(list)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addMonth', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['month'] = df['date'].dt.month\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'getMockupData', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'getMockupData2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport random\nfrom random import randint\nimport datetime\n\n#table= table_to_frame(df)\nsalespersons=[\'john\',\'peter\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'smith\',\'adam\',\'mike\',\'joe\',\'joe\',\'joe\',\'frank\',\'frank\',\'paul\']\nproducts= [\n           {"name":"p1","price":100},\n           {"name":"p2","price":150},\n           {"name":"p3","price":200},\n           {"name":"p4","price":200},\n           {"name":"p5","price":150},\n           {"name":"p6","price":300},\n           {"name":"p7","price":400},\n           {"name":"p8","price":500},\n           {"name":"p9","price":600},\n           {"name":"p10","price":1000}\n           ]\nlocations= [\'BKK\',\'Bangkok\',\'bkk\',\'Phuket\',\'PHUKET\',None]\nlist = []\nfor tran_id in range(1,10000+1):\n    cust_id     = random.randrange(1, 100+1)\n    p_idx       = random.randrange(0,10)\n    product_id  = products[p_idx]["name"]\n    price       = products[p_idx]["price"]\n    location    = random.choice(locations)\n    date        = datetime.date(randint(2022,2022), randint(1,3),randint(1,28))\n    custAnnualIncome = random.randrange(10000, 200000)\n    if date.month ==1:\n        maxqty  = 2\n        saleperson  = random.choice(salespersons[0:8])\n    elif date.month ==2:\n        maxqty  = 6\n        saleperson  =  random.choice(salespersons[9:10])\n    else:\n        maxqty  = 4\n        saleperson  =  random.choice(salespersons[11:16])\n    qty         = random.randrange(1,maxqty+1)\n     \n    tran = {\n            "tran_id":tran_id,\n            "cust_id":cust_id,\n            "product_id":product_id,\n            "qty":qty,\n            "price":price,\n            "location":location,\n            "date":date,\n            "saleperson":saleperson\n    }\n    list.append(tran)\n\ndup_index = range(1,100)\nfor idx in dup_index:\n    i = random.randrange(1,10000)\n    list.append(list[i])\ndf = pd.DataFrame.from_dict(list)\n\n\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'addTotal', 'script': "from Orange.data.pandas_compat import table_from_frame,table_to_frame\ndf= table_to_frame(in_data)\n\ndf['total'] = df['qty'] * df['price']\n\nout_data = table_from_frame(df)", 'filename': None}, {'name': 'scrape', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport time\nimport os\nfrom selenium.webdriver.common.by import By\nfrom selenium import webdriver\nfrom bs4 import BeautifulSoup\nfrom selenium.webdriver.common.keys import Keys\nimport pandas as pd\n# browser = webdriver.Chrome()\n\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nbrowser = webdriver.Chrome(ChromeDriverManager().install())\n\nbrowser.get("https://pantip.com/home/hitz")\ntime.sleep(1)\n\nelem = browser.find_element(By.TAG_NAME,"body")\n\nno_of_pagedowns = 2\n\nwhile no_of_pagedowns:\n    elem.send_keys(Keys.PAGE_DOWN)\n    time.sleep(0.2)\n    no_of_pagedowns-=1\n\npage_source = browser.page_source\ns = BeautifulSoup(page_source,"html.parser")\nlist1 = [] \nlist2 = []\n\nMyli=s.find_all(\'li\',attrs={\'class\':\'pt-list-item\'})\nfor num in range(len(Myli)):\n    obj={} #สร้าง dict ชั่วคราว\n    tags = []\n    topicText         =   Myli[num].find(\'h2\').get_text()\n    obj[\'topic\']      =   topicText\n    ttags             =   Myli[num].find(\'div\',attrs={\'class\':\'pt-list-item__tag\'})\n    if ttags is None:\n        continue\n    tempList=[]\n    for tag in ttags.find_all(\'a\'):  #หา tag แต่ละตัว\n        sTag = tag.get_text()\n        tags.append(sTag)\n        list2.append(sTag)\n\n    obj[\'tags\']       = ",".join(tags)\n    tcomment          =   Myli[num].find(\'span\',attrs={\'class\':\'pt-li_stats-comment\'})\n    obj[\'num\']        =   int(tcomment.get_text().replace(\'message\',\'\'))\n    tlink             =   Myli[num].find(\'a\',attrs={\'class\':\'gtm-hitz-link\'})\n    obj[\'link\']       =   tlink[\'href\']\n    list1.append(obj)\n\nwords = set(list2)\n\ndf=pd.DataFrame(list1)\ndf2=pd.DataFrame({"tag":list2})\ntable1 = table_from_frame(df)\nout_data = table_from_frame(df)', 'filename': None}, {'name': 'thaitoken', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'thaitoken2', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp1', 'script': 'from Orange.data.pandas_compat import table_from_frame,table_to_frame\nfrom pythainlp.corpus.common import thai_stopwords\nfrom pythainlp import word_tokenize\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport pandas as pd\nos.system(\'cls\' if os.name == \'nt\' else \'clear\')\nthai_stopwords = list(thai_stopwords())\n\ndf= table_to_frame(in_data)\n\ndef text_process(text):\n    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", \'"\', "ๆ", "ฯ"))\n    final = word_tokenize(final)\n    final = " ".join(word for word in final)\n    final = " ".join(word for word in final.split() \n                     if word.lower not in thai_stopwords)\n    return final\ndf[\'text_tokens\'] = df[\'text\'].apply(text_process)\n\nX = df[[\'text_tokens\']]\ny = df[\'sentiment\']]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\ncvec = CountVectorizer(analyzer=lambda x:x.split(\' \'))\ncvec.fit_transform(X_train[\'text_tokens\'])\n# print(cvec.vocabulary_)\n#display word cloud\n# df_pos = df[df[\'sentiment\'] == \'neg\']\n# pos_word_all = " ".join(text for text in df_pos[\'text_tokens\'])\n# reg = r"[ก-๙a-zA-Z\']+"\n# fp = \'/Users/mac/Desktop/THSarabunNew.ttf\'\n# wordcloud = WordCloud(stopwords=thai_stopwords, background_color = \'white\', max_words=2000, height = 2000, width=4000, font_path=fp, regexp=reg).generate(pos_word_all)\n# plt.figure(figsize = (16,8))\n# plt.imshow(wordcloud)\n# plt.axis(\'off\')\n# plt.show()\ntrain_bow = cvec.transform(X_train[\'text_tokens\'])\n\ndf2 =pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names_out(), index=X_train[\'text_tokens\'])\ndf2[\'sentiment\'] = df[\'sentiment\']\n\n\nmodel = LogisticRegression()\nmodel.fit(train_bow, y_train)\n\ntest_bow = cvec.transform(X_test[\'text_tokens\'])\ntest_predictions = model.predict(test_bow)\nprint(classification_report(test_predictions, y_test))\nmy_text = \'ดีมากครับส่งไว\'\nmy_tokens = text_process(my_text)\nmy_bow = cvec.transform(pd.Series([my_tokens]))\nmy_predictions = lr.predict(my_bow)\nprint(my_predictions)\nout_data = table_from_frame(df2)', 'filename': None}, {'name': 'lp2', 'script': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'filename': None}, {'name': 'lp3', 'script': '#Detailer time: Car A – 1.5 days; Car B – 3 days.\n\n#import pulp need pulp object\nfrom pulp import *   # no need to use pulp object\nmodel = LpProblem(\'car production problem\',LpMaximize)\nA =     LpVariable(\'A\',lowBound=0,cat=\'Integer\') #num of car type A to be produced\nB =     LpVariable(\'B\',lowBound=0,cat=\'Integer\') #num of car type B to be produced\nprofitA = 30000;\nprofitB = 45000;\n\n#objective function\nmodel += profitA*A + profitB*B, "Profit"  \n\n# Constraints\nmodel += 3 * A + 4 * B &lt;= 30\nmodel += 5 * A + 6 * B &lt;= 60\nmodel += 1.5 * A + 3 * B &lt;= 21\nprint(model)\n\nmodel.solve()\n\nprint("result: {}".format(LpStatus[model.status]))\n\nprint("Production of Car A = {}".format(A.varValue) )\nprint("Production of Car B = {}".format(B.varValue) )\nprint("cost: {}".format(pulp.value(model.objective)) )', 'filename': None}], 'scriptText': 'from pulp import *\n\n#1 initialize the model\nmodel = LpProblem(name=\'optimize bakery production\', sense=LpMaximize)\n\n#2 define the decision/feature variables\nA = LpVariable(\'A\',lowBound=0,cat="Integer")\nB = LpVariable(\'B\',lowBound=0,cat="Integer")\n\n#3 define the objective function\nmodel += 20*A + 40*B\n#4 define the constraints\nmodel += 0.5*A + B &lt;=30\nmodel += A + 2.5*B &lt;=60\nmodel += A + 2*B &lt;= 15\n\n#5 solve the model\nmodel.solve()\n\n#6print out the result\nprint(A.varValue)\nprint(B.varValue)\nprofit = pulp.value(model.objective)\nprint(profit)', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\xa8\x00\x00\x01\t\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
	</node_properties>
	<session_state>
		<window_groups />
	</session_state>
</scheme>
